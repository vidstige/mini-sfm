{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure from Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Projective space\n",
    "\n",
    "Points in $ \\mathbb{P}^2 $ are represented as\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x & y & w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "The equivalent point in $ \\mathbb{R}^2 $ is\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x / w & y / w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "For points with $w \\neq 0$. Points with $w=0$ is called points as infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines are represented as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T\\mathbf{l} = 0\n",
    "$$\n",
    "\n",
    "Where \n",
    "\n",
    "$$ \\mathbf{l} = \\begin{bmatrix}\n",
    "a & b & c\n",
    "\\end{bmatrix}^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding any non-zero vector $\\mathbf{x}$ satifying the equation\n",
    "\n",
    "$$\n",
    "A\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "The nullspace is only determined up to a scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def nullspace(A, atol=1e-13, rtol=0):\n",
    "    A = np.atleast_2d(A)\n",
    "    u, s, vh = svd(A)\n",
    "    tol = max(atol, rtol * s[0])\n",
    "    nnz = (s >= tol).sum()\n",
    "    ns = vh[nnz:].conj().T\n",
    "    return ns\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "print(nullspace(A))\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 0]])\n",
    "n = nullspace(A)\n",
    "print(n)\n",
    "print(A @ n)\n",
    "k = 17\n",
    "print(A @ (k * n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projective camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projective camera $\\texttt{P}$ transforms a world point $\\mathbf{X}$ into a image point $\\mathbf{x}.$\n",
    "\n",
    "$$\\mathbf{x} = \\texttt{P}\\mathbf{X}$$\n",
    "\n",
    "Where $\\texttt{P}$ is a 3x4 matrix and the world point $\\mathbf{X}$ is a 4-vector while the imgage point $\\mathbf{x}$ is a 3-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 1.]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([\n",
    "    [20,  0, 0, -10],\n",
    "    [ 0, 20, 0, -10],\n",
    "    [ 0,  0, 1, 0],\n",
    "])\n",
    "X = [3, 4, 10, 1]\n",
    "x = P @ X\n",
    "print(x / x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera matrix $\\texttt{P}$ can be decomposed into the calibration matrix $\\texttt{K}$ and a rotation and translation pair like so\n",
    "\n",
    "$$\n",
    "\\texttt{P} = \\texttt{K}\n",
    "\\begin{bmatrix}\n",
    "\\texttt{R} & \\mathbf{t}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Sometimes the camera centre $\\tilde{C}$ is needed expicitly\n",
    "\n",
    "$$\n",
    "\\mathbf{t} = -\\texttt{R}\\tilde{C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   0.  50. 100.]\n",
      " [  0.  10.  50. 100.]\n",
      " [  0.   0.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "K = np.array([\n",
    "    [10, 0, 50],\n",
    "    [0, 10, 50],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "R = np.eye(3)\n",
    "t = np.array([10, 10, 0])\n",
    "P = K @ np.hstack([R, t[:, None]])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5dbde1fcbf47688f6e8d054fa73b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=525, description='f', max=1000, min=50), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e65f4a889b4062ae54ac26c6f672db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle\n",
    "import numgl\n",
    "from numpy.linalg import inv\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "n = 10\n",
    "x, y = np.meshgrid(np.linspace(0, width, n), np.linspace(0, height, n))\n",
    "w = np.ones(x.shape)\n",
    "# points in the image plane\n",
    "p1 = np.stack([x, y, w], axis=-1).reshape((-1, 3))\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([200, 200, 1])\n",
    "target = np.array([width/2, height/2, 0])\n",
    "plot.camera.lookat(target=target)\n",
    "def update_focal(f, ay, px, py):\n",
    "    K = np.array([\n",
    "        [f, 0, px],\n",
    "        [0, f, py],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    p2 = p1 + numgl.normalized(inv(K) @ p1.T, axis=0).T * 50\n",
    "    lines = np.hstack([p1, p2]).reshape(-1, 3)\n",
    "    \n",
    "    r = 600\n",
    "    eye = np.array([r * np.sin(ay), 0, r * np.cos(ay)])\n",
    "    plot.camera.lookat(eye=eye + target)\n",
    "    \n",
    "    plot.canvas.clear()\n",
    "    plot.lines(lines)\n",
    "    plot.lines(rectangle(width, height))\n",
    "\n",
    "interact(update_focal, f=(50, 1000), ay=(-np.pi/2, np.pi/2), px=(0, width), py=(0, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epipolar Geometry\n",
    "The geometry of two cameras depicting the same scene. \n",
    "* The _epipolar point_ is the image of the camera center of the other image. It may lie outside the visible image.\n",
    "* The _epipolar line_ is the line between the two camera centers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d4c82bfb8041e1be732c74113ff920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='ay', max=1.5707963267948966, min=-1.5707963267948966…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703aa6462c5046beb9c873de8e074960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numgl\n",
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle, transform\n",
    "\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "# world points\n",
    "n = 10\n",
    "X = np.random.normal(size=(n, 3), scale=100)\n",
    "\n",
    "def rt(pose):\n",
    "    R, C = pose[0:3, 0:3], pose[0:3, 3][:, None]\n",
    "    t = -R.T @ C\n",
    "    return R, t\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([80, 80, 1])\n",
    "\n",
    "f = 350\n",
    "K = np.array([\n",
    "    [f, 0, width/2],\n",
    "    [0, f, height/2],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "left_pose =  numgl.translate((-190,    0, 500)) @ numgl.roty(2.8)\n",
    "right_pose = numgl.translate(( 330, -100, 500)) @ numgl.roty(3.7)\n",
    "P1 = K @ np.hstack(rt(left_pose))\n",
    "P2 = K @ np.hstack(rt(right_pose))\n",
    "\n",
    "def mask_points(x, width, height):\n",
    "    mask = (x[:, 0] >= 0) * (x[:, 0] < width) * (x[:, 1] >= 0) * (x[:, 1] < height)\n",
    "    return x[mask]\n",
    "\n",
    "def update(ay):\n",
    "    center = np.array([0, 150, 0])\n",
    "    target = center\n",
    "    r = 1100\n",
    "    eye = center + np.array([r * np.sin(ay), 0, r * np.cos(ay)]) + np.array([0, -300, 0])\n",
    "    plot.camera.lookat(eye=eye, target=target)\n",
    "\n",
    "    plot.canvas.clear()\n",
    "\n",
    "    # plot world points\n",
    "    plot.circles(X)    \n",
    "    \n",
    "    # project points in left camera\n",
    "    x1 = transform(P1, X)  # transform world points using camera\n",
    "    x1 = mask_points(x1, width, height)  # mask out points outside screen\n",
    "    x1 = np.hstack([x1, np.zeros((x1.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(left_pose, x1))  # plot projected points for camera\n",
    "    plot.lines(transform(left_pose, rectangle(width, height)))\n",
    "\n",
    "    # project points in right camera\n",
    "    x2 = transform(P2, X)  # transform world points using camera\n",
    "    x2 = mask_points(x2, width, height)  # mask out points outside screen\n",
    "    x2 = np.hstack([x2, np.zeros((x2.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(right_pose, x2))  # plot projected points for camera\n",
    "    plot.lines(transform(right_pose, rectangle(width, height)))\n",
    "    \n",
    "interact(update, ay=(-np.pi/2, np.pi/2))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fundamental Matrix\n",
    "The fundamental matrix maps points in the left image to lines in the right image.\n",
    "\n",
    "$$\n",
    "\\mathbf{l'} = \\texttt{F}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "A point in the left image $\\mathbf{x}$ corresponding to the same world point $\\mathbf{X}$ will lie on the epipolar line $\\mathbf{l'}$ in the right image, so we have\n",
    "\n",
    "$$\n",
    "\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "It can be directly computed from two cameras like so\n",
    "\n",
    "$$\n",
    "\\texttt{F} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{e}'\n",
    "\\end{bmatrix}_\\times \n",
    "\\texttt{P}'\\texttt{P}^+\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.46447971e-01 -4.81326969e-01  1.12239257e+02]\n",
      " [-2.81864098e-01 -2.55593651e-14  3.38446758e+02]\n",
      " [ 1.09432008e+01 -1.82613145e+02 -3.72723058e+04]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import pinv\n",
    "\n",
    "def skew(x):\n",
    "    return np.array([\n",
    "        [    0, -x[2],  x[1]],\n",
    "        [ x[2],     0, -x[0]],\n",
    "        [-x[1],  x[0],    0]])\n",
    "\n",
    "def from_cameras(P1, P2):\n",
    "    C1 = nullspace(P1).flatten()  # camera center\n",
    "    e2 = P2 @ C1  # epipole\n",
    "    return skew(e2) @ P2 @ pinv(P1)\n",
    "\n",
    "F = from_cameras(P1, P2)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.93997891e-01]\n",
      " [-1.09396108e-01]\n",
      " [ 8.27818002e-04]]\n",
      "[[ 0.84917653]\n",
      " [-0.52810436]\n",
      " [-0.00223824]]\n"
     ]
    }
   ],
   "source": [
    "print(nullspace(F))\n",
    "print(nullspace(F.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank(A, tol=1e-13):\n",
    "    _, s, _ = svd(A)\n",
    "    return np.sum(s > tol)\n",
    "\n",
    "rank(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7810d42e1e40e2bdbd02ae82a4e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import cross\n",
    "from ipycplot import Plot2D, homogenize, dehomogenize\n",
    "def from_implicit(lines, width, height):\n",
    "    \"\"\"Create a line segment from the intersection of an implicit line with a rectangle\"\"\"\n",
    "    result = np.empty((0, 2))\n",
    "    for l in lines:\n",
    "        left = np.array([1, 0, 0])  # x = 0\n",
    "        right = np.array([1, 0, -(width - 1)])  # x = width\n",
    "        top = np.array([0, 1, 0])  # y = 0\n",
    "        bottom = np.array([0, 1, -(height - 1)])  # y = height\n",
    "        intersections = np.array([\n",
    "            cross(l, left), cross(l, right), cross(l, top), cross(l, bottom),\n",
    "        ])\n",
    "        masked = mask_points(dehomogenize(intersections.T).T, width, height)\n",
    "        result = np.append(result, masked, axis=0)\n",
    "    return result\n",
    "\n",
    "n = 7\n",
    "x1 = np.hstack([np.random.rand(n, 2) * np.array([width, height]), np.ones((n, 1))])\n",
    "\n",
    "plot = Plot2D()\n",
    "plot.lines(from_implicit((F @ x1.T).T, width, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamental Matrix from correspondences\n",
    "Using $\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}$ we can compute $\\texttt{F}$ from image correspondences alone. For a single correspondence $\\mathbf{x} \\leftrightarrow \\mathbf{x}'$ where $\\mathbf{x} = \\left [ x \\,  y \\, 1  \\right ]^T$ and $\\mathbf{x}' = \\left [ x '\\,  y' \\, 1  \\right ]^T$ we can expand the inner products like so\n",
    "\n",
    "$$\n",
    "x'xf_{11} + x'yf_{12} + xf_{13} + y'xf_{21} + y'yf_{22} + y'f_{23} + xf_{31} + yf_{32} + f_{33} = 0\n",
    "$$\n",
    "\n",
    "If we introduce a vector $ \\mathbf{f} = \\left [ f_{11}, f_{12}, f_{13}, f_{21}, f_{22}, f_{23}, f_{31}, f_{32}, f_{33} \\right ]^T $ it can be written as \n",
    "\n",
    "$$\n",
    "\\left [ x'x, x'y, x', y'x, y'y, y', x, y, 1  \\right ] \\mathbf{f} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Given several image correspondences we can stack these like so\n",
    "$$\n",
    "A\\mathbf{f} =\n",
    "\\begin{bmatrix}\n",
    "x_1'x_1 & x_1'y_1 & x_1' & y_1'x_1 & y_1'y_1 & y_1' & x_1 & y_1 & 1 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_n'x_n & x_n'y_n & x_n' & y_n'x_n & y_n'y_n & y_n' & x_n & y_n & 1 \\\\\n",
    "\\end{bmatrix} \\mathbf{f}  = \\mathbf{0}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.27769814e-06 -2.06327572e-05  4.81129352e-03]\n",
      " [-1.20825008e-05  3.63602002e-20  1.45079961e-02]\n",
      " [ 4.69095684e-04 -7.82796915e-03 -1.59772978e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "#from ipycplot import transform\n",
    "\n",
    "def normalizing_transform(p):\n",
    "    \"\"\"Isotropic point normalization. Returns a transform that transform to mean 0, 0 and mean norm=sqrt(2)\"\"\"\n",
    "    d = p.shape[1]\n",
    "    c = np.mean(p, axis=0)\n",
    "    s = np.mean(norm(p - c[None:], axis=-1))\n",
    "    T = np.diag(np.append(np.repeat(s / np.sqrt(2), d), 1))\n",
    "    T[:d, d] = c\n",
    "    return inv(T)\n",
    "\n",
    "x1 = transform(P1, X)  # transform world points using camera\n",
    "x2 = transform(P2, X)  # transform world points using camera\n",
    "\n",
    "# compute F\n",
    "def from_correspondences(x1, x2):\n",
    "    # compute normalizing transforms\n",
    "    T1 = normalizing_transform(x1)\n",
    "    T2 = normalizing_transform(x2)\n",
    "    nx1 = transform(T1, x1)\n",
    "    nx2 = transform(T2, x2)\n",
    "    A = np.vstack([(x2*x1, x2*y1, x2, y2*x1, y2*y1, y2, x1, y1, 1) for (x1, y1), (x2, y2) in zip(nx1, nx2)])\n",
    "\n",
    "    #f = nullspace(A)\n",
    "    u, s, vh = svd(A)\n",
    "    f = vh[-1].T\n",
    "    \n",
    "    F = f.reshape((3, 3))    \n",
    "    \n",
    "    # force rank 2\n",
    "    u, s, vh = svd(F)\n",
    "    s[-1] = 0\n",
    "    F = u @ np.diag(s) @ vh\n",
    "    # denormalize F matrix\n",
    "    return T2.T @ F @ T1\n",
    "\n",
    "F = from_correspondences(x1, x2)\n",
    "print(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation\n",
    "\n",
    "From the projection of world points $\\mathbf{X}$ we have\n",
    "$$\n",
    "\\mathbf{x} = \\texttt{P}\\mathbf{X} \\\\\n",
    "\\mathbf{x}' = \\texttt{P}'\\mathbf{X}\n",
    "$$\n",
    "\n",
    "The scale factor can be eliminated by using cross product, e.g. for the left image $\\mathbf{x} \\times (\\texttt{P}\\mathbf{X}) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[135.76628475  80.35837532]\n",
      " [276.970937   145.26482271]\n",
      " [237.9954386   26.69987338]\n",
      " [ 76.48781544 121.64586313]\n",
      " [159.73281201 227.33188613]\n",
      " [ 13.81023537  97.81116943]\n",
      " [214.76775148  97.02865852]\n",
      " [136.29244823 119.76802765]\n",
      " [290.47038331  72.9365592 ]\n",
      " [232.41853227  24.13531362]]\n",
      "[[135.76628475  80.35837532]\n",
      " [276.970937   145.26482271]\n",
      " [237.9954386   26.69987338]\n",
      " [ 76.48781544 121.64586313]\n",
      " [159.73281201 227.33188613]\n",
      " [ 13.81023537  97.81116943]\n",
      " [214.76775148  97.02865852]\n",
      " [136.29244823 119.76802765]\n",
      " [290.47038331  72.9365592 ]\n",
      " [232.41853227  24.13531362]]\n"
     ]
    }
   ],
   "source": [
    "def triangulate(P1, P2, x1, x2):\n",
    "    Xs = []\n",
    "    for (x1, y1), (x2, y2) in zip(x1, x2):\n",
    "        A = np.array([\n",
    "            x1 * P1[2, :] - P1[0, :],\n",
    "            y1 * P1[2, :] - P1[1, :],\n",
    "            x2 * P2[2, :] - P2[0, :],\n",
    "            y2 * P2[2, :] - P2[1, :],\n",
    "        ])\n",
    "        u, s, vh = svd(A)\n",
    "        Xs.append(vh[-1])\n",
    "    return np.array(Xs)\n",
    "        \n",
    "Xr = triangulate(P1, P2, x1, x2)  # triangulate points\n",
    "print(dehomogenize(P1 @ Xr.T).T)  # project back into image\n",
    "print(x1)  # original image points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.22311834e+01, -3.14481112e-13,  3.73622013e+02,\n",
       "        -2.02047684e+02],\n",
       "       [-7.83326910e+01,  3.50000000e+02,  6.21609968e+01,\n",
       "         1.25653807e+02],\n",
       "       [-7.83326910e-01, -9.26391209e-16,  6.21609968e-01,\n",
       "         5.32552022e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "\n",
    "def depth(P, X):\n",
    "    \"\"\"Computes the depth of a world point X given a camera P\"\"\"\n",
    "    M = P[:3, :3]\n",
    "    w = (P @ X).flatten()[2]\n",
    "    W = X.flatten()[3]\n",
    "    return np.sign(det(M)) * w / (W * norm(M[-1]))  # or M[:, 2] ?\n",
    "\n",
    "def is_infront(P, X):\n",
    "    return depth(P, X) > 0\n",
    "\n",
    "def extract_cameras(K1, K2, F, x1_test, x2_test):\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1,  0, 0],\n",
    "        [0,  0, 1],\n",
    "    ])  # orthonogal (W.T@W = W@W.T = I)\n",
    "    Z = np.array([\n",
    "        [ 0, 1, 0],\n",
    "        [-1, 0, 0],\n",
    "        [ 0, 0, 0],\n",
    "    ])  # skew-symetric (-Z = Z.T)\n",
    "    E = K2.T @ F @ K1\n",
    "    U, s, Vh = svd(E)\n",
    "    u3 = U.T[-1]\n",
    "    \n",
    "    alternatives = [\n",
    "        (U @ W @ Vh, u3),\n",
    "        (U @ W @ Vh, -u3),\n",
    "        (U @ W.T @ Vh, u3),\n",
    "        (U @ W.T @ Vh, -u3),\n",
    "    ]\n",
    "\n",
    "    P1 = K1 @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    for R, t in alternatives:\n",
    "        P2 = K2 @ np.hstack([R, t[:, None]])\n",
    "        X_test = triangulate(P1, P2, x1_test[None, :], x2_test[None, :]).flatten()\n",
    "        if is_infront(P1, X_test) and is_infront(P2, X_test):\n",
    "            return P1, P2\n",
    "\n",
    "P1, P2 = extract_cameras(K, K, F, x1[3], x2[3])\n",
    "P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Calibration matrix\n",
    "Given a set of corresponding image and world points $\\mathbf{x}_i \\leftrightarrow \\mathbf{X}_i $ compute the projective camera $\\texttt{P}$. We know the world point is projected as $\\mathbf{x} = \\texttt{P}\\mathbf{X}$. Again using the identity $ \\mathbf{v} \\times \\mathbf{v} = \\mathbf{0} $ we can write.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{0}^T & -w_i\\mathbf{X}_i^T & y_i\\mathbf{X}_i^T  \\\\ \n",
    "w_i\\mathbf{X}_i^T & \\mathbf{0}^T & -x_i\\mathbf{X}_i^T  \\\\ \n",
    "y_i\\mathbf{X}_i^T & x_i\\mathbf{X}_i^T & \\mathbf{0}^T\n",
    "\\end{bmatrix} \\mathbf{p} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{x}_i = \\left [ x_i, y_i, w_i \\right ] ^T $ and $\\mathbf{p}$ is the elements of $\\texttt{P}$.\n",
    "\n",
    "Furthermore there are only two lineary independent equation and one can be omitted, giving two equations for each correspondance. The $\\texttt{P}$ matrix have 11 degrees of freedom (12 for the elements or $\\texttt{P}$, minus one for overall scale) so 5½ correspondances are needed, where only the x (or y) coordinate of the last image point need to be know.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.18677686e+02  1.64056236e+02]\n",
      " [-5.15283657e+02  3.73109848e+02]\n",
      " [-8.66357434e+02 -8.29402940e+02]\n",
      " [ 4.83067511e+02  1.56018156e+02]\n",
      " [ 3.76218343e+02 -1.56470115e+03]\n",
      " [-2.25492963e+04  4.42133055e+02]\n",
      " [-2.13219306e+02  7.78513006e+01]\n",
      " [ 1.28859548e+02 -7.08690685e+01]\n",
      " [ 1.25745606e-01  4.86385551e+01]\n",
      " [-6.57599928e+01 -2.07849653e+02]]\n",
      "[[ 2.18677686e+02  1.64056236e+02]\n",
      " [-5.15283657e+02  3.73109848e+02]\n",
      " [-8.66357434e+02 -8.29402940e+02]\n",
      " [ 4.83067511e+02  1.56018156e+02]\n",
      " [ 3.76218343e+02 -1.56470115e+03]\n",
      " [-2.25492963e+04  4.42133055e+02]\n",
      " [-2.13219306e+02  7.78513006e+01]\n",
      " [ 1.28859548e+02 -7.08690685e+01]\n",
      " [ 1.25745606e-01  4.86385551e+01]\n",
      " [-6.57599928e+01 -2.07849653e+02]]\n"
     ]
    }
   ],
   "source": [
    "def compute_camera(x, X):\n",
    "    T = normalizing_transform(x)\n",
    "    U = normalizing_transform(X)\n",
    "    w = 1\n",
    "    rows = []\n",
    "    for (x, y), X in zip(transform(T, x), transform(U, X)):\n",
    "        Xh = np.append(X, 1)\n",
    "        rows.append(np.hstack([np.zeros(4), -w * Xh, y * Xh]))\n",
    "        rows.append(np.hstack([w * Xh, np.zeros(4), -x * Xh]))\n",
    "    #A = np.array(rows[:-1])  # skip last element\n",
    "    A = np.array(rows)\n",
    "    u, s, vh = svd(A)\n",
    "    P = vh[-1].reshape((3, 4))\n",
    "    return inv(T) @ P @ U  # denormalize\n",
    "\n",
    "x1 = transform(P1, X)\n",
    "#P = compute_camera(x1[0:6], X[0:6])\n",
    "P = compute_camera(x1, X)\n",
    "print(transform(P, X))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using thee RQ-factorization $A = RQ$ for any matrix $A$ where $R$ is a _right_ (upper) triangular matrix and $Q$ is an orthonogal matrix,  we can find the Calibration Matrix from a projective camera $P$.\n",
    "\n",
    "$$\n",
    "\\texttt{P} = \\begin{bmatrix} \\texttt{M} | -\\texttt{M}\\tilde{C} \\end{bmatrix} = \\begin{bmatrix} \\texttt{KR} | -\\texttt{KR}\\tilde{C} \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.50000000e+02,  6.76790241e-13,  1.60000000e+02],\n",
       "        [ 0.00000000e+00, -3.50000000e+02,  1.00000000e+02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]),\n",
       " array([[-1.00000000e+00, -1.37456338e-15, -5.03599125e-16],\n",
       "        [-1.37456338e-15,  1.00000000e+00,  3.15631928e-16],\n",
       "        [ 5.03599125e-16,  3.15631928e-16, -1.00000000e+00]]),\n",
       " array([ 1.27885835e-13,  1.38247921e-13, -1.04792445e-13]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import rq\n",
    "\n",
    "def decompose_camera(P):\n",
    "    M = P[:3, :3]\n",
    "    K, R = rq(M)\n",
    "    T = np.diag(np.sign(np.diag(K)))\n",
    "    if det(T) < 0:\n",
    "        T[1, 1] *= -1\n",
    "    K = K @ T\n",
    "    K = K / K[-1, -1]  # normalize with K[2, 2] == 1\n",
    "    C = inv(-M) @ P[:,3]\n",
    "    return K, T @ R, C\n",
    "\n",
    "decompose_camera(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe52b68863541c98b2c0f16914bcf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from ipycanvas import Canvas\n",
    "import PIL\n",
    "\n",
    "class Clicker:\n",
    "    def __init__(self, filename):\n",
    "        im = PIL.Image.open(filename)\n",
    "        self.canvas = Canvas()\n",
    "        self.scale = self.canvas.width / im.width\n",
    "        self.im = im.resize((int(im.width * self.scale), int(im.height * self.scale)))\n",
    "        self.canvas.put_image_data(np.array(self.im), 0, 0)\n",
    "        self.canvas.on_mouse_down(self)\n",
    "        self._clicks = []\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.canvas.stroke_style = 'white'\n",
    "        self.canvas.stroke_circle(x, y, 5)\n",
    "        self._clicks.append((x, y))\n",
    "\n",
    "    def plot(self, clicks):\n",
    "        self.canvas.stroke_style = 'white'\n",
    "        self.canvas.stroke_circles(clicker1.scale * x1[:, 0], clicker1.scale * x1[:, 1], 5 * np.ones(len(x1)))\n",
    "        \n",
    "    def clicks(self):\n",
    "        return np.array(self._clicks) / self.scale  # scale clicks back to image resolution\n",
    "\n",
    "clicker = Clicker('data/calibration-target.jpeg')\n",
    "clicker.canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.66510775e+03, -2.99768229e+01,  3.62447692e+02],\n",
       "        [ 0.00000000e+00, -1.54767174e+03, -1.28572941e+02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]),\n",
       " array([[-0.44117229, -0.89498438,  0.06610571],\n",
       "        [-0.42298704,  0.27234152,  0.86424074],\n",
       "        [-0.79148529,  0.35331721, -0.49871633]]),\n",
       " array([1141.13955478, -293.01708214, 1022.96564233]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measured image points\n",
    "xc = np.load('calibration-points.npy')\n",
    "#xc = clicker.clicks()\n",
    "#xc[:, 1] = height - xc[:, 1]  # negate y-coordinates\n",
    "#print(2816, 1880)  # original resolution\n",
    "\n",
    "# measured world points\n",
    "XC = np.array([\n",
    "    [0, 0, 17],  # top left\n",
    "    [290, 0, 17],  # top right\n",
    "    [290, 287, 17],  # bottom right\n",
    "    [0, 287, 17],  # bottom left\n",
    "    [290/2, 287/2, 17],  # mid point\n",
    "    [0, 0, 0],  # top left (lower)\n",
    "    [290, 0, 0],  # top right (lower)\n",
    "    [290, 287, 0],  # bottom right (lower)\n",
    "])\n",
    "\n",
    "P_calibration = compute_camera(xc, XC)\n",
    "P_calibration\n",
    "decompose_camera(P_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5001f2d8c71e452781922ea9a13f313c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clicker1 = Clicker('data/1.jpeg')\n",
    "x1 = np.load('1.npy')\n",
    "clicker1.plot(x1)\n",
    "clicker1.canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f4234112a240c1a31e46c28012414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clicker2 = Clicker('data/2.jpeg')\n",
    "x2 = np.load('2.npy')\n",
    "clicker2.plot(x2)\n",
    "clicker2.canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1 = clicker1.clicks()\n",
    "#np.save('1.npy', x1)\n",
    "#print(x1)\n",
    "\n",
    "#x2 = clicker2.clicks()\n",
    "#np.save('2.npy', x2)\n",
    "#print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27998147e-08,  1.09764908e-07, -1.30345206e-04],\n",
       "       [ 6.55048038e-08, -1.15224107e-08, -1.64132369e-03],\n",
       "       [ 1.05392905e-04,  1.50475198e-03, -5.19222591e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = from_correspondences(x1, x2)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89bd6c7606447cc9cfbad8007ee0db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = Plot2D()\n",
    "plot.image(np.array(clicker1.im))\n",
    "plot.canvas.stroke_style = 'white'\n",
    "plot.lines(from_implicit((F @ homogenize(clicker1.scale * x1.T)).T, clicker1.im.width, clicker1.im.width))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

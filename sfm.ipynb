{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure from Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Projective space\n",
    "\n",
    "Points in $ \\mathbb{P}^2 $ are represented as\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x & y & w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "The equivalent point in $ \\mathbb{R}^2 $ is\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x / w & y / w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "For points with $w \\neq 0$. Points with $w=0$ is called points as infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines are represented as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T\\mathbf{l} = 0\n",
    "$$\n",
    "\n",
    "Where \n",
    "\n",
    "$$ \\mathbf{l} = \\begin{bmatrix}\n",
    "a & b & c\n",
    "\\end{bmatrix}^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding any non-zero vector $\\mathbf{x}$ satifying the equation\n",
    "\n",
    "$$\n",
    "A\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "The nullspace is only determined up to a scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def nullspace(A, atol=1e-13, rtol=0):\n",
    "    A = np.atleast_2d(A)\n",
    "    u, s, vh = svd(A)\n",
    "    tol = max(atol, rtol * s[0])\n",
    "    nnz = (s >= tol).sum()\n",
    "    ns = vh[nnz:].conj().T\n",
    "    return ns\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "print(nullspace(A))\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 0]])\n",
    "n = nullspace(A)\n",
    "print(n)\n",
    "print(A @ n)\n",
    "k = 17\n",
    "print(A @ (k * n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projective camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projective camera $\\texttt{P}$ transforms a world point $\\mathbf{X}$ into a image point $\\mathbf{x}.$\n",
    "\n",
    "$$\\mathbf{x} = \\texttt{P}\\mathbf{X}$$\n",
    "\n",
    "Where $\\texttt{P}$ is a 3x4 matrix and the world point $\\mathbf{X}$ is a 4-vector while the imgage point $\\mathbf{x}$ is a 3-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 1.]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([\n",
    "    [20,  0, 0, -10],\n",
    "    [ 0, 20, 0, -10],\n",
    "    [ 0,  0, 1, 0],\n",
    "])\n",
    "X = [3, 4, 10, 1]\n",
    "x = P @ X\n",
    "# todo plot this\n",
    "print(x / x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera matrix $\\texttt{P}$ can be decomposed into the calibration matrix $\\texttt{K}$ and a rotation and translation pair like so\n",
    "\n",
    "$$\n",
    "\\texttt{P} = \\texttt{K}\n",
    "\\begin{bmatrix}\n",
    "\\texttt{R} & \\mathbf{t}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Sometimes the camera centre $\\tilde{C}$ is needed expicitly\n",
    "\n",
    "$$\n",
    "\\mathbf{t} = -\\texttt{R}\\tilde{C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   0.  50. 100.]\n",
      " [  0.  10.  50. 100.]\n",
      " [  0.   0.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "K = np.array([\n",
    "    [10, 0, 50],\n",
    "    [0, 10, 50],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "R = np.eye(3)\n",
    "t = np.array([10, 10, 0])\n",
    "P = K @ np.hstack([R, t[:, None]])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11582355074406e8818d4f1d8833a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=525, description='f', max=1000, min=50), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd84e581965d4e2a873d00a2b59b49e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle\n",
    "import numgl\n",
    "from numpy.linalg import inv\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "n = 10\n",
    "x, y = np.meshgrid(np.linspace(0, width, n), np.linspace(0, height, n))\n",
    "w = np.ones(x.shape)\n",
    "# points in the image plane\n",
    "p1 = np.stack([x, y, w], axis=-1).reshape((-1, 3))\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([200, 200, 1])\n",
    "target = np.array([width/2, height/2, 0])\n",
    "plot.camera.lookat(target=target)\n",
    "def update_focal(f, ay, px, py):\n",
    "    K = np.array([\n",
    "        [f, 0, px],\n",
    "        [0, f, py],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    p2 = p1 + numgl.normalized(inv(K) @ p1.T, axis=0).T * 50\n",
    "    lines = np.hstack([p1, p2]).reshape(-1, 3)\n",
    "    \n",
    "    r = 600\n",
    "    eye = np.array([r * np.sin(ay), 0, r * np.cos(ay)])\n",
    "    plot.camera.lookat(eye=eye + target)\n",
    "    \n",
    "    plot.canvas.clear()\n",
    "    plot.lines(lines)\n",
    "    plot.lines(rectangle(width, height))\n",
    "\n",
    "interact(update_focal, f=(50, 1000), ay=(-np.pi/2, np.pi/2), px=(0, width), py=(0, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epipolar Geometry\n",
    "The geometry of two cameras depicting the same scene. \n",
    "* The _epipolar point_ is the image of the camera center of the other image. It may lie outside the visible image.\n",
    "* The _epipolar line_ is the line between the two camera centers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eea08bed5f417fa2378336ff2235b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='ay', max=1.5707963267948966, min=-1.5707963267948966…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd52a78c5a584243a493c6b7739e01bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numgl\n",
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle, transform\n",
    "\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "# world points\n",
    "n = 10\n",
    "X = np.random.normal(size=(n, 3), scale=100)\n",
    "\n",
    "def rt(pose):\n",
    "    R, C = pose[0:3, 0:3], pose[0:3, 3][:, None]\n",
    "    t = -R.T @ C\n",
    "    return R, t\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([80, 80, 1])\n",
    "\n",
    "f = 350\n",
    "K = np.array([\n",
    "    [f, 0, width/2],\n",
    "    [0, f, height/2],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "left_pose =  numgl.translate((-190,    0, 500)) @ numgl.roty(2.8)\n",
    "right_pose = numgl.translate(( 330, -100, 500)) @ numgl.roty(3.7)\n",
    "P1 = K @ np.hstack(rt(left_pose))\n",
    "P2 = K @ np.hstack(rt(right_pose))\n",
    "\n",
    "def mask_points(x, width, height):\n",
    "    mask = (x[:, 0] >= 0) * (x[:, 0] < width) * (x[:, 1] >= 0) * (x[:, 1] < height)\n",
    "    return x[mask]\n",
    "\n",
    "def update(ay):\n",
    "    center = np.array([0, 150, 0])\n",
    "    target = center\n",
    "    r = 1100\n",
    "    eye = center + np.array([r * np.sin(ay), 0, r * np.cos(ay)]) + np.array([0, -300, 0])\n",
    "    plot.camera.lookat(eye=eye, target=target)\n",
    "\n",
    "    plot.canvas.clear()\n",
    "\n",
    "    # plot world points\n",
    "    plot.circles(X)    \n",
    "    \n",
    "    # project points in left camera\n",
    "    \n",
    "    x1 = transform(P1, X)  # transform world points using camera\n",
    "    x1 = mask_points(x1, width, height)  # mask out points outside screen\n",
    "    x1 = np.hstack([x1, np.zeros((x1.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(left_pose, x1))  # plot projected points for camera\n",
    "    plot.lines(transform(left_pose, rectangle(width, height)))\n",
    "\n",
    "    # project points in right camera\n",
    "    x2 = transform(P2, X)  # transform world points using camera\n",
    "    x2 = mask_points(x2, width, height)  # mask out points outside screen\n",
    "    x2 = np.hstack([x2, np.zeros((x2.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(right_pose, x2))  # plot projected points for camera\n",
    "    plot.lines(transform(right_pose, rectangle(width, height)))\n",
    "    \n",
    "interact(update, ay=(-np.pi/2, np.pi/2))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fundamental Matrix\n",
    "The fundamental matrix maps points in the left image to lines in the right image.\n",
    "\n",
    "$$\n",
    "\\mathbf{l'} = \\texttt{F}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "A point in the left image $\\mathbf{x}$ corresponding to the same world point $\\mathbf{X}$ will lie on the epipolar line $\\mathbf{l'}$ in the right image, so we have\n",
    "\n",
    "$$\n",
    "\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "It can be directly computed from two cameras like so\n",
    "\n",
    "$$\n",
    "\\texttt{F} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{e}'\n",
    "\\end{bmatrix}_\\times \n",
    "\\texttt{P}'\\texttt{P}^+\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.46447971e-01 -4.81326969e-01  1.12239257e+02]\n",
      " [-2.81864098e-01 -2.55593651e-14  3.38446758e+02]\n",
      " [ 1.09432008e+01 -1.82613145e+02 -3.72723058e+04]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import pinv\n",
    "\n",
    "def skew(x):\n",
    "    return np.array([\n",
    "        [    0, -x[2],  x[1]],\n",
    "        [ x[2],     0, -x[0]],\n",
    "        [-x[1],  x[0],    0]])\n",
    "\n",
    "def from_cameras(P1, P2):\n",
    "    C1 = nullspace(P1).flatten()  # camera center\n",
    "    e2 = P2 @ C1  # epipole\n",
    "    return skew(e2) @ P2 @ pinv(P1)\n",
    "\n",
    "F = from_cameras(P1, P2)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.93997891e-01]\n",
      " [-1.09396108e-01]\n",
      " [ 8.27818002e-04]]\n",
      "[[ 0.84917653]\n",
      " [-0.52810436]\n",
      " [-0.00223824]]\n"
     ]
    }
   ],
   "source": [
    "print(nullspace(F))\n",
    "print(nullspace(F.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank(A, tol=1e-13):\n",
    "    _, s, _ = svd(A)\n",
    "    return np.sum(s > tol)\n",
    "\n",
    "rank(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76.22235019 79.14229478  1.        ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92adcb93ad5f401f8d1df609ed085222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import cross\n",
    "from ipycplot import Plot2D, dehomogenize\n",
    "def from_implicit(l, width, height):\n",
    "    \"\"\"Create a line segment from the intersection of an implicit line with a rectangle\"\"\"\n",
    "    left = np.array([1, 0, 0])  # x = 0\n",
    "    right = np.array([1, 0, -(width - 1)])  # x = width\n",
    "    top = np.array([0, 1, 0])  # y = 0\n",
    "    bottom = np.array([0, 1, -(height - 1)])  # y = height\n",
    "    intersections = np.array([\n",
    "        cross(l, left), cross(l, right), cross(l, top), cross(l, bottom),\n",
    "    ])\n",
    "    masked = mask_points(dehomogenize(intersections.T).T, width, height)\n",
    "    return masked\n",
    "\n",
    "x1 = np.hstack([np.random.rand(2) * np.array([width, height]), 1])  # random image point\n",
    "print(x1)\n",
    "\n",
    "plot = Plot2D()\n",
    "plot.lines(from_implicit(F@x1, width, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamental Matrix from correspondances\n",
    "Using $\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}$ we can compute $\\texttt{F}$ from image correspondances alone. For a single correspondance $\\mathbf{x} \\leftrightarrow \\mathbf{x}'$ where $\\mathbf{x} = \\left [ x \\,  y \\, 1  \\right ]^T$ and $\\mathbf{x}' = \\left [ x '\\,  y' \\, 1  \\right ]^T$ we can expand the inner products like so\n",
    "\n",
    "$$\n",
    "x'xf_{11} + x'yf_{12} + xf_{13} + y'xf_{21} + y'yf_{22} + y'f_{23} + xf_{31} + yf_{32} + f_{33} = 0\n",
    "$$\n",
    "\n",
    "If we introduce a vector $ \\mathbf{f} = \\left [ f_{11}, f_{12}, f_{13}, f_{21}, f_{22}, f_{23}, f_{31}, f_{32}, f_{33} \\right ]^T $ it can be written as \n",
    "\n",
    "$$\n",
    "\\left [ x'x, x'y, x', y'x, y'y, y', x, y, 1  \\right ] \\mathbf{f} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Given several image correspondances we can stack these like so\n",
    "$$\n",
    "A\\mathbf{f} =\n",
    "\\begin{bmatrix}\n",
    "x_1'x_1 & x_1'y_1 & x_1' & y_1'x_1 & y_1'y_1 & y_1' & x_1 & y_1 & 1 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_n'x_n & x_n'y_n & x_n' & y_n'x_n & y_n'y_n & y_n' & x_n & y_n & 1 \\\\\n",
    "\\end{bmatrix} \\mathbf{f}  = \\mathbf{0}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.60597401e-06 -1.84250179e-05  4.29647712e-03]\n",
      " [-1.07896531e-05  1.22840156e-19  1.29556164e-02]\n",
      " [ 4.18901667e-04 -6.99036345e-03 -1.42677004e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "#from ipycplot import transform\n",
    "\n",
    "def normalizing_transform(p):\n",
    "    \"\"\"Isotropic point normalization. Returns a transform that transform to mean 0, 0 and mean norm=sqrt(2)\"\"\"\n",
    "    d = p.shape[1]\n",
    "    c = np.mean(p, axis=0)\n",
    "    s = np.mean(norm(p - c[None:], axis=-1))\n",
    "    T = np.diag(np.append(np.repeat(s / np.sqrt(2), d), 1))\n",
    "    T[:d, d] = c\n",
    "    return inv(T)\n",
    "\n",
    "x1 = transform(P1, X)  # transform world points using camera\n",
    "x2 = transform(P2, X)  # transform world points using camera\n",
    "\n",
    "# compute F\n",
    "def from_correspondances(x1, x2):\n",
    "    # compute normalizing transforms\n",
    "    T1 = normalizing_transform(x1)\n",
    "    T2 = normalizing_transform(x2)\n",
    "    nx1 = transform(T1, x1)\n",
    "    nx2 = transform(T2, x2)\n",
    "    A = np.vstack([(x2*x1, x2*y1, x2, y2*x1, y2*y1, y2, x1, y1, 1) for (x1, y1), (x2, y2) in zip(nx1, nx2)])\n",
    "    f = nullspace(A)\n",
    "    F = f.reshape((3, 3))    \n",
    "    \n",
    "    # force rank 2\n",
    "    u, s, vh = svd(F)\n",
    "    s[-1] = 0\n",
    "    F = u @ np.diag(s) @ vh\n",
    "    # denormalize F matrix\n",
    "    return T2.T @ F @ T1\n",
    "\n",
    "F = from_correspondances(x1, x2)\n",
    "print(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation\n",
    "\n",
    "From the projection of world points $\\mathbf{X}$ we have\n",
    "$$\n",
    "\\mathbf{x} = \\texttt{P}\\mathbf{X} \\\\\n",
    "\\mathbf{x}' = \\texttt{P}'\\mathbf{X}\n",
    "$$\n",
    "\n",
    "The scale factor can be eliminated by using cross product, e.g. for the left image $\\mathbf{x} \\times (\\texttt{P}\\mathbf{X}) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[212.34845377 192.68864587]\n",
      " [112.42891359 -18.82272787]\n",
      " [142.27561959   3.17213829]\n",
      " [156.552468   190.21129105]\n",
      " [-33.65852172 202.33931989]\n",
      " [108.93650612  61.35366805]\n",
      " [ 98.77996051 -11.40693062]\n",
      " [164.35632093 102.87057697]\n",
      " [195.16971962 173.91660457]\n",
      " [123.59658315 134.64195198]]\n",
      "[[212.34845377 192.68864587]\n",
      " [112.42891359 -18.82272787]\n",
      " [142.27561959   3.17213829]\n",
      " [156.552468   190.21129105]\n",
      " [-33.65852172 202.33931989]\n",
      " [108.93650612  61.35366805]\n",
      " [ 98.77996051 -11.40693062]\n",
      " [164.35632093 102.87057697]\n",
      " [195.16971962 173.91660457]\n",
      " [123.59658315 134.64195198]]\n"
     ]
    }
   ],
   "source": [
    "def triangulate(P1, P2, x1, x2):\n",
    "    Xs = []\n",
    "    for (x1, y1), (x2, y2) in zip(x1, x2):\n",
    "        A = np.array([\n",
    "            x1 * P1[2, :] - P1[0, :],\n",
    "            y1 * P1[2, :] - P1[1, :],\n",
    "            x2 * P2[2, :] - P2[0, :],\n",
    "            y2 * P2[2, :] - P2[1, :],\n",
    "        ])\n",
    "        u, s, vh = svd(A)\n",
    "        Xs.append(vh[-1])\n",
    "    return np.array(Xs)\n",
    "        \n",
    "Xr = triangulate(P1, P2, x1, x2)  # triangulate points\n",
    "print(dehomogenize(P1 @ Xr.T).T)  # project back into image\n",
    "print(x1)  # original image points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dcbb4b9a426b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mP1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mP1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_cameras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mP2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dcbb4b9a426b>\u001b[0m in \u001b[0;36mextract_cameras\u001b[0;34m(K1, K2, F, x1_test, x2_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mK1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mu3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     alternatives = [\n",
      "\u001b[0;31mNameError\u001b[0m: name 'u' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "\n",
    "def depth(P, X):\n",
    "    \"\"\"Computes the depth of a world point X given a camera P\"\"\"\n",
    "    M = P[:3, :3]\n",
    "    w = (P @ X).flatten()[2]\n",
    "    W = X.flatten()[3]\n",
    "    return np.sign(det(M)) * w / (W * norm(M[-1]))  # or M[:, 2] ?\n",
    "\n",
    "def is_infront(P, X):\n",
    "    return depth(P, X) > 0\n",
    "\n",
    "def extract_cameras(K1, K2, F, x1_test, x2_test):\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1,  0, 0],\n",
    "        [0,  0, 1],\n",
    "    ])  # orthonogal (W.T@W = W@W.T = I)\n",
    "    Z = np.array([\n",
    "        [ 0, 1, 0],\n",
    "        [-1, 0, 0],\n",
    "        [ 0, 0, 0],\n",
    "    ])  # skew-symetric (-Z = Z.T)\n",
    "    E = K2.T @ F @ K1\n",
    "    U, s, Vh = svd(E)\n",
    "    u3 = u.T[-1]\n",
    "    \n",
    "    alternatives = [\n",
    "        (U @ W @ Vh, u3),\n",
    "        (U @ W @ Vh, -u3),\n",
    "        (U @ W.T @ Vh, u3),\n",
    "        (U @ W.T @ Vh, -u3),\n",
    "    ]\n",
    "\n",
    "    P1 = K1 @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    for R, t in alternatives:\n",
    "        P2 = K2 @ np.hstack([R, t[:, None]])\n",
    "        X_test = triangulate(P1, P2, x1_test[None, :], x2_test[None, :]).flatten()\n",
    "        if is_infront(P1, X_test) and is_infront(P2, X_test):\n",
    "            return P1, P2\n",
    "\n",
    "P1, P2 = extract_cameras(K, K, F, x1[3], x2[3])\n",
    "P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Calibration matrix\n",
    "Given a set of corresponding image and world points $\\mathbf{x}_i \\leftrightarrow \\mathbf{X}_i $ compute the projective camera $\\texttt{P}$. We know the world point is projected as $\\mathbf{x} = \\texttt{P}\\mathbf{X}$. Again using the identity $ \\mathbf{v} \\times \\mathbf{v} = \\mathbf{0} $ we can write.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{0}^T & -w_i\\mathbf{X}_i^T & y_i\\mathbf{X}_i^T  \\\\ \n",
    "w_i\\mathbf{X}_i^T & \\mathbf{0}^T & -x_i\\mathbf{X}_i^T  \\\\ \n",
    "y_i\\mathbf{X}_i^T & x_i\\mathbf{X}_i^T & \\mathbf{0}^T\n",
    "\\end{bmatrix} \\mathbf{p} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{x}_i = \\left [ x_i, y_i, w_i \\right ] ^T $ and $\\mathbf{p}$ is the elements of $\\texttt{P}$.\n",
    "\n",
    "Furthermore there are only two lineary independent equation and one can be omitted, giving two equations for each correspondance. The $\\texttt{P}$ matrix have 11 degrees of freedom (12 for the elements or $\\texttt{P}$, minus one for overall scale) so 5½ correspondances are needed, where only the x (or y) coordinate of the last image point need to be know.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 12)\n",
      "[5.71781009 4.48047389 3.77104957 2.51633528 2.2933038  1.97691709\n",
      " 1.24746913 0.86037107 0.58535061 0.49283896 0.0412408 ]\n",
      "[[212.34845377 192.68864587]\n",
      " [112.42891359 -18.82272787]\n",
      " [142.27561959   3.17213829]\n",
      " [156.552468   190.21129105]\n",
      " [-33.65852172 202.33931989]\n",
      " [108.93650612  61.35366805]\n",
      " [ 98.77996051 -11.40693062]\n",
      " [164.35632093 102.87057697]\n",
      " [195.16971962 173.91660457]\n",
      " [123.59658315 134.64195198]]\n",
      "[[212.34845377 192.68864587]\n",
      " [112.42891359 -18.82272787]\n",
      " [142.27561959   3.17213829]\n",
      " [156.552468   190.21129105]\n",
      " [-33.65852172 202.33931989]\n",
      " [108.93650612  61.35366805]\n",
      " [ 98.77996051 -11.40693062]\n",
      " [164.35632093 102.87057697]\n",
      " [195.16971962 173.91660457]\n",
      " [123.59658315 134.64195198]]\n"
     ]
    }
   ],
   "source": [
    "def compute_camera(x, X):\n",
    "    T = normalizing_transform(x)\n",
    "    U = normalizing_transform(X)\n",
    "    w = 1\n",
    "    rows = []\n",
    "    for (x, y), X in zip(transform(T, x), transform(U, X)):\n",
    "        Xh = np.append(X, 1)\n",
    "        rows.append(np.hstack([np.zeros(4), -w * Xh, y * Xh]))\n",
    "        rows.append(np.hstack([w * Xh, np.zeros(4), -x * Xh]))\n",
    "    A = np.array(rows[:-1])  # skip last element\n",
    "    u, s, vh = svd(A)\n",
    "    P = vh[-1].reshape((3, 4))\n",
    "    return inv(T) @ P @ U  # denormalize\n",
    "\n",
    "\n",
    "x1 = transform(P1, X)\n",
    "P = compute_camera(x1[0:6], X[0:6])\n",
    "print(transform(P, X))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

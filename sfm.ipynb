{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure from Motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Projective space\n",
    "\n",
    "Points in $ \\mathbb{P}^2 $ are represented as\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x & y & w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "The equivalent point in $ \\mathbb{R}^2 $ is\n",
    "\n",
    "$$ \\mathbf{x} = \\begin{bmatrix}\n",
    "x / w & y / w\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "For points with $w \\neq 0$. Points with $w=0$ is called points as infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lines are represented as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T\\mathbf{l} = 0\n",
    "$$\n",
    "\n",
    "Where \n",
    "\n",
    "$$ \\mathbf{l} = \\begin{bmatrix}\n",
    "a & b & c\n",
    "\\end{bmatrix}^T\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding any non-zero vector $\\mathbf{x}$ satifying the equation\n",
    "\n",
    "$$\n",
    "A\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "The nullspace is only determined up to a scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[0.]\n",
      " [1.]]\n",
      "[[0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def nullspace(A, atol=1e-13, rtol=0):\n",
    "    A = np.atleast_2d(A)\n",
    "    u, s, vh = svd(A)\n",
    "    tol = max(atol, rtol * s[0])\n",
    "    nnz = (s >= tol).sum()\n",
    "    ns = vh[nnz:].conj().T\n",
    "    return ns\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "print(nullspace(A))\n",
    "\n",
    "A = np.array([[1, 0],\n",
    "              [0, 0]])\n",
    "n = nullspace(A)\n",
    "print(n)\n",
    "print(A @ n)\n",
    "k = 17\n",
    "print(A @ (k * n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projective camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projective camera $\\texttt{P}$ transforms a world point $\\mathbf{X}$ into a image point $\\mathbf{x}.$\n",
    "\n",
    "$$\\mathbf{x} = \\texttt{P}\\mathbf{X}$$\n",
    "\n",
    "Where $\\texttt{P}$ is a 3x4 matrix and the world point $\\mathbf{X}$ is a 4-vector while the imgage point $\\mathbf{x}$ is a 3-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 7. 1.]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([\n",
    "    [20,  0, 0, -10],\n",
    "    [ 0, 20, 0, -10],\n",
    "    [ 0,  0, 1, 0],\n",
    "])\n",
    "X = [3, 4, 10, 1]\n",
    "x = P @ X\n",
    "print(x / x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera matrix $\\texttt{P}$ can be decomposed into the calibration matrix $\\texttt{K}$ and a rotation and translation pair like so\n",
    "\n",
    "$$\n",
    "\\texttt{P} = \\texttt{K}\n",
    "\\begin{bmatrix}\n",
    "\\texttt{R} & \\mathbf{t}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Sometimes the camera centre $\\tilde{C}$ is needed expicitly\n",
    "\n",
    "$$\n",
    "\\mathbf{t} = -\\texttt{R}\\tilde{C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.   0.  50. 100.]\n",
      " [  0.  10.  50. 100.]\n",
      " [  0.   0.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "K = np.array([\n",
    "    [10, 0, 50],\n",
    "    [0, 10, 50],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "R = np.eye(3)\n",
    "t = np.array([10, 10, 0])\n",
    "P = K @ np.hstack([R, t[:, None]])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc559cbf81ee475aadfaa4ee06dc8ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=525, description='f', max=1000, min=50), FloatSlider(value=0.0, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adaa7a5f43a4ed9947a54abffef6eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle\n",
    "import numgl\n",
    "from numpy.linalg import inv\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "n = 10\n",
    "x, y = np.meshgrid(np.linspace(0, width, n), np.linspace(0, height, n))\n",
    "w = np.ones(x.shape)\n",
    "# points in the image plane\n",
    "p1 = np.stack([x, y, w], axis=-1).reshape((-1, 3))\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([200, 200, 1])\n",
    "target = np.array([width/2, height/2, 0])\n",
    "plot.camera.lookat(target=target)\n",
    "def update_focal(f, ay, px, py):\n",
    "    K = np.array([\n",
    "        [f, 0, px],\n",
    "        [0, f, py],\n",
    "        [0, 0, 1],\n",
    "    ])\n",
    "    p2 = p1 + numgl.normalized(inv(K) @ p1.T, axis=0).T * 50\n",
    "    lines = np.hstack([p1, p2]).reshape(-1, 3)\n",
    "    \n",
    "    r = 600\n",
    "    eye = np.array([r * np.sin(ay), 0, r * np.cos(ay)])\n",
    "    plot.camera.lookat(eye=eye + target)\n",
    "    \n",
    "    plot.canvas.clear()\n",
    "    plot.lines(lines)\n",
    "    plot.lines(rectangle(width, height))\n",
    "\n",
    "interact(update_focal, f=(50, 1000), ay=(-np.pi/2, np.pi/2), px=(0, width), py=(0, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epipolar Geometry\n",
    "The geometry of two cameras depicting the same scene. \n",
    "* The _epipolar point_ is the image of the camera center of the other image. It may lie outside the visible image.\n",
    "* The _epipolar line_ is the line between the two camera centers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754906bdb5584053a576f1eac70f482f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='ay', max=1.5707963267948966, min=-1.5707963267948966…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a59bb719f25419a910688a6474772c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numgl\n",
    "from ipywidgets import interact\n",
    "from ipycplot import Plot3D, rectangle, transform\n",
    "\n",
    "\n",
    "width, height = 320, 200\n",
    "\n",
    "# world points\n",
    "n = 10\n",
    "X = np.random.normal(size=(n, 3), scale=100)\n",
    "\n",
    "def rt(pose):\n",
    "    R, C = pose[0:3, 0:3], pose[0:3, 3][:, None]\n",
    "    t = -R.T @ C\n",
    "    return R, t\n",
    "\n",
    "plot = Plot3D()\n",
    "plot.scale = np.array([80, 80, 1])\n",
    "\n",
    "f = 350\n",
    "K = np.array([\n",
    "    [f, 0, width/2],\n",
    "    [0, f, height/2],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "left_pose =  numgl.translate((-190,    0, 500)) @ numgl.roty(2.8)\n",
    "right_pose = numgl.translate(( 330, -100, 500)) @ numgl.roty(3.7)\n",
    "P1 = K @ np.hstack(rt(left_pose))\n",
    "P2 = K @ np.hstack(rt(right_pose))\n",
    "\n",
    "def mask_points(x, width, height):\n",
    "    mask = (x[:, 0] >= 0) * (x[:, 0] < width) * (x[:, 1] >= 0) * (x[:, 1] < height)\n",
    "    return x[mask]\n",
    "\n",
    "def update(ay):\n",
    "    center = np.array([0, 150, 0])\n",
    "    target = center\n",
    "    r = 1100\n",
    "    eye = center + np.array([r * np.sin(ay), 0, r * np.cos(ay)]) + np.array([0, -300, 0])\n",
    "    plot.camera.lookat(eye=eye, target=target)\n",
    "\n",
    "    plot.canvas.clear()\n",
    "\n",
    "    # plot world points\n",
    "    plot.circles(X)    \n",
    "    \n",
    "    # project points in left camera\n",
    "    x1 = transform(P1, X)  # transform world points using camera\n",
    "    x1 = mask_points(x1, width, height)  # mask out points outside screen\n",
    "    x1 = np.hstack([x1, np.zeros((x1.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(left_pose, x1))  # plot projected points for camera\n",
    "    plot.lines(transform(left_pose, rectangle(width, height)))\n",
    "\n",
    "    # project points in right camera\n",
    "    x2 = transform(P2, X)  # transform world points using camera\n",
    "    x2 = mask_points(x2, width, height)  # mask out points outside screen\n",
    "    x2 = np.hstack([x2, np.zeros((x2.shape[0], 1))])  # add z=0 coordinate\n",
    "    plot.circles(transform(right_pose, x2))  # plot projected points for camera\n",
    "    plot.lines(transform(right_pose, rectangle(width, height)))\n",
    "    \n",
    "interact(update, ay=(-np.pi/2, np.pi/2))\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fundamental Matrix\n",
    "The fundamental matrix maps points in the left image to lines in the right image.\n",
    "\n",
    "$$\n",
    "\\mathbf{l'} = \\texttt{F}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "A point in the left image $\\mathbf{x}$ corresponding to the same world point $\\mathbf{X}$ will lie on the epipolar line $\\mathbf{l'}$ in the right image, so we have\n",
    "\n",
    "$$\n",
    "\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "It can be directly computed from two cameras like so\n",
    "\n",
    "$$\n",
    "\\texttt{F} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{e}'\n",
    "\\end{bmatrix}_\\times \n",
    "\\texttt{P}'\\texttt{P}^+\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.46447971e-01 -4.81326969e-01  1.12239257e+02]\n",
      " [-2.81864098e-01 -2.55593651e-14  3.38446758e+02]\n",
      " [ 1.09432008e+01 -1.82613145e+02 -3.72723058e+04]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import pinv\n",
    "\n",
    "def skew(x):\n",
    "    return np.array([\n",
    "        [    0, -x[2],  x[1]],\n",
    "        [ x[2],     0, -x[0]],\n",
    "        [-x[1],  x[0],    0]])\n",
    "\n",
    "def from_cameras(P1, P2):\n",
    "    C1 = nullspace(P1).flatten()  # camera center\n",
    "    e2 = P2 @ C1  # epipole\n",
    "    return skew(e2) @ P2 @ pinv(P1)\n",
    "\n",
    "F = from_cameras(P1, P2)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.93997891e-01]\n",
      " [-1.09396108e-01]\n",
      " [ 8.27818002e-04]]\n",
      "[[ 0.84917653]\n",
      " [-0.52810436]\n",
      " [-0.00223824]]\n"
     ]
    }
   ],
   "source": [
    "print(nullspace(F))\n",
    "print(nullspace(F.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank(A, tol=1e-13):\n",
    "    _, s, _ = svd(A)\n",
    "    return np.sum(s > tol)\n",
    "\n",
    "rank(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38.36272096 133.02831556   1.        ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaf5530ec2e4b63a914c84bfa633170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import cross\n",
    "from ipycplot import Plot2D, dehomogenize\n",
    "def from_implicit(l, width, height):\n",
    "    \"\"\"Create a line segment from the intersection of an implicit line with a rectangle\"\"\"\n",
    "    left = np.array([1, 0, 0])  # x = 0\n",
    "    right = np.array([1, 0, -(width - 1)])  # x = width\n",
    "    top = np.array([0, 1, 0])  # y = 0\n",
    "    bottom = np.array([0, 1, -(height - 1)])  # y = height\n",
    "    intersections = np.array([\n",
    "        cross(l, left), cross(l, right), cross(l, top), cross(l, bottom),\n",
    "    ])\n",
    "    masked = mask_points(dehomogenize(intersections.T).T, width, height)\n",
    "    return masked\n",
    "\n",
    "x1 = np.hstack([np.random.rand(2) * np.array([width, height]), 1])  # random image point\n",
    "print(x1)\n",
    "\n",
    "plot = Plot2D()\n",
    "plot.lines(from_implicit(F@x1, width, height))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fundamental Matrix from correspondances\n",
    "Using $\\mathbf{x'}^T\\texttt{F}\\mathbf{x} = \\mathbf{0}$ we can compute $\\texttt{F}$ from image correspondances alone. For a single correspondance $\\mathbf{x} \\leftrightarrow \\mathbf{x}'$ where $\\mathbf{x} = \\left [ x \\,  y \\, 1  \\right ]^T$ and $\\mathbf{x}' = \\left [ x '\\,  y' \\, 1  \\right ]^T$ we can expand the inner products like so\n",
    "\n",
    "$$\n",
    "x'xf_{11} + x'yf_{12} + xf_{13} + y'xf_{21} + y'yf_{22} + y'f_{23} + xf_{31} + yf_{32} + f_{33} = 0\n",
    "$$\n",
    "\n",
    "If we introduce a vector $ \\mathbf{f} = \\left [ f_{11}, f_{12}, f_{13}, f_{21}, f_{22}, f_{23}, f_{31}, f_{32}, f_{33} \\right ]^T $ it can be written as \n",
    "\n",
    "$$\n",
    "\\left [ x'x, x'y, x', y'x, y'y, y', x, y, 1  \\right ] \\mathbf{f} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Given several image correspondances we can stack these like so\n",
    "$$\n",
    "A\\mathbf{f} =\n",
    "\\begin{bmatrix}\n",
    "x_1'x_1 & x_1'y_1 & x_1' & y_1'x_1 & y_1'y_1 & y_1' & x_1 & y_1 & 1 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_n'x_n & x_n'y_n & x_n' & y_n'x_n & y_n'y_n & y_n' & x_n & y_n & 1 \\\\\n",
    "\\end{bmatrix} \\mathbf{f}  = \\mathbf{0}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.70048131e-06  1.87356327e-05 -4.36890850e-03]\n",
      " [ 1.09715486e-05  4.45687894e-21 -1.31740263e-02]\n",
      " [-4.25963645e-04  7.10820923e-03  1.45082299e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "#from ipycplot import transform\n",
    "\n",
    "def normalizing_transform(p):\n",
    "    \"\"\"Isotropic point normalization. Returns a transform that transform to mean 0, 0 and mean norm=sqrt(2)\"\"\"\n",
    "    d = p.shape[1]\n",
    "    c = np.mean(p, axis=0)\n",
    "    s = np.mean(norm(p - c[None:], axis=-1))\n",
    "    T = np.diag(np.append(np.repeat(s / np.sqrt(2), d), 1))\n",
    "    T[:d, d] = c\n",
    "    return inv(T)\n",
    "\n",
    "x1 = transform(P1, X)  # transform world points using camera\n",
    "x2 = transform(P2, X)  # transform world points using camera\n",
    "\n",
    "# compute F\n",
    "def from_correspondances(x1, x2):\n",
    "    # compute normalizing transforms\n",
    "    T1 = normalizing_transform(x1)\n",
    "    T2 = normalizing_transform(x2)\n",
    "    nx1 = transform(T1, x1)\n",
    "    nx2 = transform(T2, x2)\n",
    "    A = np.vstack([(x2*x1, x2*y1, x2, y2*x1, y2*y1, y2, x1, y1, 1) for (x1, y1), (x2, y2) in zip(nx1, nx2)])\n",
    "    f = nullspace(A)\n",
    "    F = f.reshape((3, 3))    \n",
    "    \n",
    "    # force rank 2\n",
    "    u, s, vh = svd(F)\n",
    "    s[-1] = 0\n",
    "    F = u @ np.diag(s) @ vh\n",
    "    # denormalize F matrix\n",
    "    return T2.T @ F @ T1\n",
    "\n",
    "F = from_correspondances(x1, x2)\n",
    "print(F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation\n",
    "\n",
    "From the projection of world points $\\mathbf{X}$ we have\n",
    "$$\n",
    "\\mathbf{x} = \\texttt{P}\\mathbf{X} \\\\\n",
    "\\mathbf{x}' = \\texttt{P}'\\mathbf{X}\n",
    "$$\n",
    "\n",
    "The scale factor can be eliminated by using cross product, e.g. for the left image $\\mathbf{x} \\times (\\texttt{P}\\mathbf{X}) = \\mathbf{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2005.21307868 -1558.86561392]\n",
      " [ 1149.2139094   -383.50647672]\n",
      " [ -216.27872734    96.79469838]\n",
      " [ -629.3173952   -219.98691667]\n",
      " [ 1716.53163421   -68.56387496]\n",
      " [ 4944.01034483 -1478.35962367]\n",
      " [ 4566.75583641   701.57300009]\n",
      " [ -507.83498339    79.10301826]\n",
      " [ 5745.00702865 -5267.94816272]\n",
      " [ -830.55079491   721.40716682]]\n",
      "[[  314.54106327 -1765.70323711]\n",
      " [ 1063.11634169  -561.49043587]\n",
      " [ -195.16745908     7.40447076]\n",
      " [ -157.11735481  -530.25240396]\n",
      " [ 1715.77966502   100.73015294]\n",
      " [   76.17552402 -1134.59246336]\n",
      " [ 1431.54331411  2336.18577016]\n",
      " [ -464.09487478   -84.72650929]\n",
      " [  218.41669655 -5411.35819329]\n",
      " [ -193.53793964   947.53441481]]\n"
     ]
    }
   ],
   "source": [
    "def triangulate(P1, P2, x1, x2):\n",
    "    Xs = []\n",
    "    for (x1, y1), (x2, y2) in zip(x1, x2):\n",
    "        A = np.array([\n",
    "            x1 * P1[2, :] - P1[0, :],\n",
    "            y1 * P1[2, :] - P1[1, :],\n",
    "            x2 * P2[2, :] - P2[0, :],\n",
    "            y2 * P2[2, :] - P2[1, :],\n",
    "        ])\n",
    "        u, s, vh = svd(A)\n",
    "        Xs.append(vh[-1])\n",
    "    return np.array(Xs)\n",
    "        \n",
    "Xr = triangulate(P1, P2, x1, x2)  # triangulate points\n",
    "print(dehomogenize(P1 @ Xr.T).T)  # project back into image\n",
    "print(x1)  # original image points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.22311834e+01,  6.53804457e-14,  3.73622013e+02,\n",
       "        -2.02047684e+02],\n",
       "       [-7.83326910e+01,  3.50000000e+02,  6.21609968e+01,\n",
       "         1.25653807e+02],\n",
       "       [-7.83326910e-01,  4.38420285e-16,  6.21609968e-01,\n",
       "         5.32552022e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "\n",
    "def depth(P, X):\n",
    "    \"\"\"Computes the depth of a world point X given a camera P\"\"\"\n",
    "    M = P[:3, :3]\n",
    "    w = (P @ X).flatten()[2]\n",
    "    W = X.flatten()[3]\n",
    "    return np.sign(det(M)) * w / (W * norm(M[-1]))  # or M[:, 2] ?\n",
    "\n",
    "def is_infront(P, X):\n",
    "    return depth(P, X) > 0\n",
    "\n",
    "def extract_cameras(K1, K2, F, x1_test, x2_test):\n",
    "    W = np.array([\n",
    "        [0, -1, 0],\n",
    "        [1,  0, 0],\n",
    "        [0,  0, 1],\n",
    "    ])  # orthonogal (W.T@W = W@W.T = I)\n",
    "    Z = np.array([\n",
    "        [ 0, 1, 0],\n",
    "        [-1, 0, 0],\n",
    "        [ 0, 0, 0],\n",
    "    ])  # skew-symetric (-Z = Z.T)\n",
    "    E = K2.T @ F @ K1\n",
    "    U, s, Vh = svd(E)\n",
    "    u3 = U.T[-1]\n",
    "    \n",
    "    alternatives = [\n",
    "        (U @ W @ Vh, u3),\n",
    "        (U @ W @ Vh, -u3),\n",
    "        (U @ W.T @ Vh, u3),\n",
    "        (U @ W.T @ Vh, -u3),\n",
    "    ]\n",
    "\n",
    "    P1 = K1 @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "    for R, t in alternatives:\n",
    "        P2 = K2 @ np.hstack([R, t[:, None]])\n",
    "        X_test = triangulate(P1, P2, x1_test[None, :], x2_test[None, :]).flatten()\n",
    "        if is_infront(P1, X_test) and is_infront(P2, X_test):\n",
    "            return P1, P2\n",
    "\n",
    "P1, P2 = extract_cameras(K, K, F, x1[3], x2[3])\n",
    "P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Calibration matrix\n",
    "Given a set of corresponding image and world points $\\mathbf{x}_i \\leftrightarrow \\mathbf{X}_i $ compute the projective camera $\\texttt{P}$. We know the world point is projected as $\\mathbf{x} = \\texttt{P}\\mathbf{X}$. Again using the identity $ \\mathbf{v} \\times \\mathbf{v} = \\mathbf{0} $ we can write.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{0}^T & -w_i\\mathbf{X}_i^T & y_i\\mathbf{X}_i^T  \\\\ \n",
    "w_i\\mathbf{X}_i^T & \\mathbf{0}^T & -x_i\\mathbf{X}_i^T  \\\\ \n",
    "y_i\\mathbf{X}_i^T & x_i\\mathbf{X}_i^T & \\mathbf{0}^T\n",
    "\\end{bmatrix} \\mathbf{p} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{x}_i = \\left [ x_i, y_i, w_i \\right ] ^T $ and $\\mathbf{p}$ is the elements of $\\texttt{P}$.\n",
    "\n",
    "Furthermore there are only two lineary independent equation and one can be omitted, giving two equations for each correspondance. The $\\texttt{P}$ matrix have 11 degrees of freedom (12 for the elements or $\\texttt{P}$, minus one for overall scale) so 5½ correspondances are needed, where only the x (or y) coordinate of the last image point need to be know.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[164.37057713  15.54325001]\n",
      " [ 76.37751296  83.18891806]\n",
      " [145.72606285  53.53563954]\n",
      " [189.81434548  72.65854778]\n",
      " [118.99446926  69.64306354]\n",
      " [301.69583752 185.9372603 ]\n",
      " [134.42968618  96.14116797]\n",
      " [141.01026722 179.2065657 ]\n",
      " [101.99247559 139.2354128 ]\n",
      " [102.94029865  -9.95690082]]\n",
      "[[164.37057713  15.54325001]\n",
      " [ 76.37751296  83.18891806]\n",
      " [145.72606285  53.53563954]\n",
      " [189.81434548  72.65854778]\n",
      " [118.99446926  69.64306354]\n",
      " [301.69583752 185.9372603 ]\n",
      " [134.42968618  96.14116797]\n",
      " [141.01026722 179.2065657 ]\n",
      " [101.99247559 139.2354128 ]\n",
      " [102.94029865  -9.95690082]]\n"
     ]
    }
   ],
   "source": [
    "def compute_camera(x, X):\n",
    "    T = normalizing_transform(x)\n",
    "    U = normalizing_transform(X)\n",
    "    w = 1\n",
    "    rows = []\n",
    "    for (x, y), X in zip(transform(T, x), transform(U, X)):\n",
    "        Xh = np.append(X, 1)\n",
    "        rows.append(np.hstack([np.zeros(4), -w * Xh, y * Xh]))\n",
    "        rows.append(np.hstack([w * Xh, np.zeros(4), -x * Xh]))\n",
    "    #A = np.array(rows[:-1])  # skip last element\n",
    "    A = np.array(rows)\n",
    "    u, s, vh = svd(A)\n",
    "    P = vh[-1].reshape((3, 4))\n",
    "    return inv(T) @ P @ U  # denormalize\n",
    "\n",
    "x1 = transform(P1, X)\n",
    "#P = compute_camera(x1[0:6], X[0:6])\n",
    "P = compute_camera(x1, X)\n",
    "print(transform(P, X))\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using thee RQ-factorization $A = RQ$ for any matrix $A$ where $R$ is a _right_ (upper) triangular matrix and $Q$ is an orthonogal matrix,  we can find the Calibration Matrix from a projective camera $P$.\n",
    "\n",
    "$$\n",
    "\\texttt{P} = \\begin{bmatrix} \\texttt{M} | -\\texttt{M}\\tilde{C} \\end{bmatrix} = \\begin{bmatrix} \\texttt{KR} | -\\texttt{KR}\\tilde{C} \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.50000000e+02, 8.02941227e-13, 1.60000000e+02],\n",
       "        [0.00000000e+00, 3.50000000e+02, 1.00000000e+02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       " array([[ 1.00000000e+00, -1.08875962e-15,  7.13491545e-16],\n",
       "        [ 1.08875962e-15,  1.00000000e+00, -5.18902942e-16],\n",
       "        [-7.13491545e-16,  5.18902942e-16,  1.00000000e+00]]),\n",
       " array([-2.81153576e-13,  4.37403709e-13, -1.38954217e-13]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import rq\n",
    "\n",
    "def decompose_camera(P):\n",
    "    M = P[:3, :3]\n",
    "    K, R = rq(M)\n",
    "    T = np.diag(np.sign(np.diag(K)))\n",
    "    if det(T) < 0:\n",
    "        T[1, 1] *= -1\n",
    "    K = K @ T\n",
    "    K = K / K[-1, -1]  # normalize with K[2, 2] == 1\n",
    "    C = inv(-M) @ P[:,3]\n",
    "    return K, T @ R, C\n",
    "\n",
    "decompose_camera(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0611f8fad9c4a11b607f10654742a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from ipycanvas import Canvas\n",
    "import PIL\n",
    "\n",
    "class Clicker:\n",
    "    def __init__(self, filename):\n",
    "        im = PIL.Image.open(filename)\n",
    "        self.canvas = Canvas()\n",
    "        self.scale = canvas.width / im.width\n",
    "        im = im.resize((int(im.width * self.scale), int(im.height * self.scale)))\n",
    "        self.canvas.put_image_data(np.array(im), 0, 0)\n",
    "        self.canvas.on_mouse_down(self)\n",
    "        self._clicks = []\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.canvas.stroke_style = 'white'\n",
    "        self.canvas.stroke_circle(x, y, 5)\n",
    "        self._clicks.append((x, y))\n",
    "    \n",
    "    def clicks(self):\n",
    "        return np.array(self._clicks) / self.scale  # scale clicks back to image resolution\n",
    "\n",
    "clicker = Clicker('data/calibration-target.jpeg')\n",
    "clicker.canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816 1880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 6.98158543e+03,  8.63341925e+02,  2.07900374e+03],\n",
       "        [ 0.00000000e+00, -6.55047914e+03,  9.06390618e+02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]),\n",
       " array([[ 0.4158937 ,  0.90479446, -0.09153918],\n",
       "        [-0.40891106,  0.27596188,  0.86984872],\n",
       "        [ 0.81229562, -0.32433322,  0.48475127]]),\n",
       " array([1151.9509305 , -423.56252163, 1103.55719924]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measured image points\n",
    "xc = clicker.clicks()\n",
    "xc[:, 1] = height - xc[:, 1]  # negate y-coordinates\n",
    "print(2816, 1880)  # original resolution\n",
    "# measured world points\n",
    "XC = np.array([\n",
    "    [0, 0, 17],  # top left\n",
    "    [290, 0, 17],  # top right\n",
    "    [290, 287, 17],  # bottom right\n",
    "    [0, 287, 17],  # bottom left\n",
    "    [290/2, 287/2, 17],  # mid point\n",
    "    [0, 0, 0],  # top left (lower)\n",
    "    [290, 0, 0],  # top right (lower)\n",
    "    [290, 287, 0],  # bottom right (lower)\n",
    "])\n",
    "\n",
    "P_calibration = compute_camera(xc, XC)\n",
    "P_calibration\n",
    "decompose_camera(P_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceaac757faa4c198e721f5f72b0ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "left_clicker = Clicker('data/1.jpeg')\n",
    "left_clicker.canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
